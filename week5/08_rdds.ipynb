{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab34abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/04 18:56:37 WARN Utils: Your hostname, Bronx.local resolves to a loopback address: 127.0.0.1; using 192.168.1.112 instead (on interface en0)\n",
      "23/03/04 18:56:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/04 18:56:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName('test') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d042aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832a9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSELECT\\n    -- Revenue grouping\\n    date_trunc('hour', lpep_pickup_datetime) AS hour,\\n    PULocationID AS zone,\\n    SUM(total_amount) AS amount,\\n    COUNT(1) AS number_records\\n    FROM \\n        green\\n    WHERE\\n        lpep_pickup_datetime >= '2020-01-01 00:00:00'\\n    GROUP BY 1, 2\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "SELECT\n",
    "    -- Revenue grouping\n",
    "    date_trunc('hour', lpep_pickup_datetime) AS hour,\n",
    "    PULocationID AS zone,\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "    FROM \n",
    "        green\n",
    "    WHERE\n",
    "        lpep_pickup_datetime >= '2020-01-01 00:00:00'\n",
    "    GROUP BY 1, 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f2a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 22, 13, 18, 32), lpep_dropoff_datetime=datetime.datetime(2020, 1, 22, 13, 45, 58), store_and_fwd_flag='N', RatecodeID=1, PULocationID=244, DOLocationID=41, passenger_count=1, trip_distance=5.22, fare_amount=22.0, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=22.8, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 17, 54, 10), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 18, 1, 2), store_and_fwd_flag='N', RatecodeID=1, PULocationID=236, DOLocationID=263, passenger_count=1, trip_distance=0.87, fare_amount=6.5, extra=1.0, mta_tax=0.5, tip_amount=1.2, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=12.25, payment_type=1, trip_type=1, congestion_surcharge=2.75),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 19, 10, 23, 37), lpep_dropoff_datetime=datetime.datetime(2020, 1, 19, 10, 26, 29), store_and_fwd_flag='N', RatecodeID=1, PULocationID=166, DOLocationID=166, passenger_count=4, trip_distance=0.63, fare_amount=4.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=5.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 21, 14, 25, 16), lpep_dropoff_datetime=datetime.datetime(2020, 1, 21, 14, 35, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=152, DOLocationID=238, passenger_count=1, trip_distance=2.71, fare_amount=11.0, extra=0.0, mta_tax=0.5, tip_amount=2.91, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=17.46, payment_type=1, trip_type=1, congestion_surcharge=2.75),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 7, 9, 46), lpep_dropoff_datetime=datetime.datetime(2020, 1, 7, 9, 59), store_and_fwd_flag=None, RatecodeID=None, PULocationID=51, DOLocationID=3, passenger_count=None, trip_distance=2.13, fare_amount=18.96, extra=2.75, mta_tax=0.0, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=22.01, payment_type=None, trip_type=None, congestion_surcharge=None)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df is built on top of rdd of rows\n",
    "df_green.rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1afdb6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 22, 13, 18, 32), lpep_dropoff_datetime=datetime.datetime(2020, 1, 22, 13, 45, 58), store_and_fwd_flag='N', RatecodeID=1, PULocationID=244, DOLocationID=41, passenger_count=1, trip_distance=5.22, fare_amount=22.0, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=22.8, payment_type=1, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 17, 54, 10), lpep_dropoff_datetime=datetime.datetime(2020, 1, 23, 18, 1, 2), store_and_fwd_flag='N', RatecodeID=1, PULocationID=236, DOLocationID=263, passenger_count=1, trip_distance=0.87, fare_amount=6.5, extra=1.0, mta_tax=0.5, tip_amount=1.2, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=12.25, payment_type=1, trip_type=1, congestion_surcharge=2.75),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 19, 10, 23, 37), lpep_dropoff_datetime=datetime.datetime(2020, 1, 19, 10, 26, 29), store_and_fwd_flag='N', RatecodeID=1, PULocationID=166, DOLocationID=166, passenger_count=4, trip_distance=0.63, fare_amount=4.5, extra=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=5.3, payment_type=2, trip_type=1, congestion_surcharge=0.0),\n",
       " Row(VendorID=2, lpep_pickup_datetime=datetime.datetime(2020, 1, 21, 14, 25, 16), lpep_dropoff_datetime=datetime.datetime(2020, 1, 21, 14, 35, 51), store_and_fwd_flag='N', RatecodeID=1, PULocationID=152, DOLocationID=238, passenger_count=1, trip_distance=2.71, fare_amount=11.0, extra=0.0, mta_tax=0.5, tip_amount=2.91, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=17.46, payment_type=1, trip_type=1, congestion_surcharge=2.75),\n",
       " Row(VendorID=None, lpep_pickup_datetime=datetime.datetime(2020, 1, 7, 9, 46), lpep_dropoff_datetime=datetime.datetime(2020, 1, 7, 9, 59), store_and_fwd_flag=None, RatecodeID=None, PULocationID=51, DOLocationID=3, passenger_count=None, trip_distance=2.13, fare_amount=18.96, extra=2.75, mta_tax=0.0, tip_amount=0.0, tolls_amount=0.0, ehail_fee=None, improvement_surcharge=0.3, total_amount=22.01, payment_type=None, trip_type=None, congestion_surcharge=None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_green.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c806c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = df_green \\\n",
    "        .select('lpep_pickup_datetime', 'PULocationID', 'total_amount') \\\n",
    "        .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff598421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 22, 13, 18, 32), PULocationID=244, total_amount=22.8),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 23, 17, 54, 10), PULocationID=236, total_amount=12.25),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 19, 10, 23, 37), PULocationID=166, total_amount=5.3),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 21, 14, 25, 16), PULocationID=152, total_amount=17.46),\n",
       " Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 7, 9, 46), PULocationID=51, total_amount=22.01)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de131a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of lambda we can use python functions\n",
    "\n",
    "def filter_outliers(row):\n",
    "    return row.lpep_pickup_datetime >= start\n",
    "\n",
    "# lambda function which can be inside filter:\n",
    "# lambda row: row.lpep_pickup_datetime >= start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28371515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(lpep_pickup_datetime=datetime.datetime(2020, 1, 22, 13, 18, 32), PULocationID=244, total_amount=22.8)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start = datetime(year=2020, month=1, day=1)\n",
    "rdd.filter(filter_outliers).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf904b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = rdd.take(10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e56c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 1, 22, 13, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aab61cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# key = (Hour, Zone)\n",
    "# value - (amt, count)\n",
    "\n",
    "def prepare_for_grouping(row):\n",
    "    hour = row.lpep_pickup_datetime.replace(minute=0, second=0, microsecond=0)\n",
    "    zone = row.PULocationID\n",
    "    key = (hour, zone)\n",
    "    \n",
    "    amount = row.total_amount\n",
    "    count = 1\n",
    "    value = (amount, count)\n",
    "    \n",
    "    return (key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3514579d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 22, 13, 0), 244), (22.8, 1)),\n",
       " ((datetime.datetime(2020, 1, 23, 17, 0), 236), (12.25, 1)),\n",
       " ((datetime.datetime(2020, 1, 19, 10, 0), 166), (5.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 21, 14, 0), 152), (17.46, 1)),\n",
       " ((datetime.datetime(2020, 1, 7, 9, 0), 51), (22.01, 1)),\n",
       " ((datetime.datetime(2020, 1, 10, 8, 0), 32), (52.68, 1)),\n",
       " ((datetime.datetime(2020, 1, 15, 10, 0), 130), (78.36, 1)),\n",
       " ((datetime.datetime(2020, 1, 26, 16, 0), 7), (12.09, 1)),\n",
       " ((datetime.datetime(2020, 1, 24, 21, 0), 244), (42.0, 1)),\n",
       " ((datetime.datetime(2020, 1, 27, 23, 0), 65), (15.3, 1))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd \\\n",
    "    .filter(filter_outliers) \\\n",
    "    .map(prepare_for_grouping) \\\n",
    "    .take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd643879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce by key\n",
    "# input rdd (key, value) ---> output (key, reduced value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1bf0fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce\n",
    "def calculate_revenue(left_value, right_value):\n",
    "   \n",
    "    left_amount, left_count = left_value\n",
    "    right_amount, right_count = right_value\n",
    "    \n",
    "    output_amount = left_amount + right_amount\n",
    "    output_count = left_count + right_count\n",
    "   \n",
    "    return (output_amount, output_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe33f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a great example of filter, map, reduce \n",
    "# filter is similar to select, if filters the RDD\n",
    "# map prepares for grouping, we take each row, and transform then into (key, value) \n",
    "#     where key is the (hour, zone), since we will group them by hour and by zone\n",
    "#     where value is (amount, count), since we wanted to calculate sum of amount and count them\n",
    "# reduce is when we do the final calculation of grouping them and calculating\n",
    "\n",
    "rdd_new = rdd \\\n",
    "            .filter(filter_outliers) \\\n",
    "            .map(prepare_for_grouping) \\\n",
    "            .reduceByKey(calculate_revenue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46430207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve RDD 27 with partitions 0\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\n",
      "\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n",
      "Exception in thread \"serve RDD 32 with partitions 0\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\n",
      "\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((datetime.datetime(2020, 1, 21, 13, 0), 33), (535.8900000000001, 26)),\n",
       " ((datetime.datetime(2020, 1, 18, 11, 0), 128), (33.51, 1)),\n",
       " ((datetime.datetime(2020, 1, 19, 9, 0), 166), (782.1999999999998, 46)),\n",
       " ((datetime.datetime(2020, 1, 15, 21, 0), 42), (336.1400000000001, 23)),\n",
       " ((datetime.datetime(2020, 1, 4, 12, 0), 116), (119.85, 8)),\n",
       " ((datetime.datetime(2020, 1, 8, 20, 0), 197), (10.3, 1)),\n",
       " ((datetime.datetime(2020, 1, 19, 0, 0), 25), (142.75000000000003, 11)),\n",
       " ((datetime.datetime(2020, 1, 3, 15, 0), 166), (639.56, 39)),\n",
       " ((datetime.datetime(2020, 1, 24, 19, 0), 166), (739.6099999999997, 48)),\n",
       " ((datetime.datetime(2020, 1, 27, 8, 0), 63), (99.96000000000001, 3))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_new.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c34d1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "RevenueRow = namedtuple('RevenueRow', ['hour', 'zone', 'revenue', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad77436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make it pretty by unnesting and add row names\n",
    "\n",
    "def unwrap(row):\n",
    "    return RevenueRow(\n",
    "            hour=row[0][0], \n",
    "            zone=row[0][1], \n",
    "            revenue=row[1][0], \n",
    "            count=row[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b2d994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "result_schema = types.StructType([\n",
    "     types.StructField('hour', types.TimestampType(), True), \n",
    "     types.StructField('zone', types.IntegerType(), True), \n",
    "     types.StructField('revenue', types.DoubleType(), True), \n",
    "     types.StructField('count', types.IntegerType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "215a8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = rdd_new.map(unwrap) \\\n",
    "                   .toDF(result_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c1285ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 29:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/04 20:09:44 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 29:===========================================>              (6 + 2) / 8]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.write.parquet('tmp/green-revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f95249d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is map partition, example we want a service that predicts the duration of a trip\n",
    "# we will define our rdd here\n",
    "columns = ['VendorID', 'lpep_pickup_datetime', 'PULocationID', 'DOLocationID', 'trip_distance']\n",
    "\n",
    "duration_rdd = df_green \\\n",
    "                .select(columns) \\\n",
    "                .rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de4202da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of map partition\n",
    "# \n",
    "\n",
    "def apply_model_in_batch(partition):\n",
    "    return [1]\n",
    "\n",
    "# collect returns a list, \n",
    "# this is going to return [1, 1, 1, 1] which means, it's returning 1 for each partition and there are four partition\n",
    "rdd.mapPartitions(apply_model_in_batch).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a72ede95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[746744, 418184, 219220, 215980, 212159, 199320, 183795, 109115]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_model_in_batch(partition):\n",
    "    # partition is not a list, but it's an iterator\n",
    "    cnt = 0\n",
    "    for row in partition:\n",
    "        cnt = cnt + 1\n",
    "    return [cnt]\n",
    "rdd.mapPartitions(apply_model_in_batch).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8f68898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a94621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = duration_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ec9338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_in_batch(rows):\n",
    "    # same results as above but using pands df\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    cnt = len(df)\n",
    "    return [cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36dc9419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[746744, 418184, 219220, 215980, 212159, 199320, 183795, 109115]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_rdd.mapPartitions(apply_model_in_batch).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e05e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pretend we have a fancy ML model\n",
    "\n",
    "def model_predict(df):\n",
    "    y_pred = df.trip_distance * 5\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d35d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model_in_batch(rows):\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    predictions = model_predict(df)\n",
    "    df['predicted_duration'] = predictions\n",
    "    for row in df.itertuples():\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "347b1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Pandas(Index=0, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-22 13:18:32'), PULocationID=244, DOLocationID=41, trip_distance=5.22, predicted_duration=26.099999999999998),\n",
       " Pandas(Index=1, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-23 17:54:10'), PULocationID=236, DOLocationID=263, trip_distance=0.87, predicted_duration=4.35),\n",
       " Pandas(Index=2, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-19 10:23:37'), PULocationID=166, DOLocationID=166, trip_distance=0.63, predicted_duration=3.15),\n",
       " Pandas(Index=3, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-21 14:25:16'), PULocationID=152, DOLocationID=238, trip_distance=2.71, predicted_duration=13.55),\n",
       " Pandas(Index=4, VendorID=nan, lpep_pickup_datetime=Timestamp('2020-01-07 09:46:00'), PULocationID=51, DOLocationID=3, trip_distance=2.13, predicted_duration=10.649999999999999),\n",
       " Pandas(Index=5, VendorID=nan, lpep_pickup_datetime=Timestamp('2020-01-10 08:19:00'), PULocationID=32, DOLocationID=186, trip_distance=17.93, predicted_duration=89.65),\n",
       " Pandas(Index=6, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-15 10:57:40'), PULocationID=130, DOLocationID=228, trip_distance=24.04, predicted_duration=120.19999999999999),\n",
       " Pandas(Index=7, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-26 16:52:02'), PULocationID=7, DOLocationID=223, trip_distance=1.45, predicted_duration=7.25),\n",
       " Pandas(Index=8, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-24 21:57:19'), PULocationID=244, DOLocationID=87, trip_distance=10.94, predicted_duration=54.699999999999996),\n",
       " Pandas(Index=9, VendorID=2.0, lpep_pickup_datetime=Timestamp('2020-01-27 23:45:54'), PULocationID=65, DOLocationID=62, trip_distance=3.18, predicted_duration=15.9)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve RDD 84\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\n",
      "\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n"
     ]
    }
   ],
   "source": [
    "duration_rdd.mapPartitions(apply_model_in_batch).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f77a0678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------------------+------------+------------+-------------+------------------+\n",
      "|Index|VendorID|lpep_pickup_datetime|PULocationID|DOLocationID|trip_distance|predicted_duration|\n",
      "+-----+--------+--------------------+------------+------------+-------------+------------------+\n",
      "|    0|     2.0|                  {}|         244|          41|         5.22|26.099999999999998|\n",
      "|    1|     2.0|                  {}|         236|         263|         0.87|              4.35|\n",
      "|    2|     2.0|                  {}|         166|         166|         0.63|              3.15|\n",
      "|    3|     2.0|                  {}|         152|         238|         2.71|             13.55|\n",
      "|    4|     NaN|                  {}|          51|           3|         2.13|10.649999999999999|\n",
      "|    5|     NaN|                  {}|          32|         186|        17.93|             89.65|\n",
      "|    6|     2.0|                  {}|         130|         228|        24.04|120.19999999999999|\n",
      "|    7|     2.0|                  {}|           7|         223|         1.45|              7.25|\n",
      "|    8|     2.0|                  {}|         244|          87|        10.94|54.699999999999996|\n",
      "|    9|     2.0|                  {}|          65|          62|         3.18|              15.9|\n",
      "|   10|     2.0|                  {}|          95|          95|         1.86|               9.3|\n",
      "|   11|     2.0|                  {}|         181|         195|         1.75|              8.75|\n",
      "|   12|     NaN|                  {}|         240|          37|        18.95|             94.75|\n",
      "|   13|     NaN|                  {}|          75|         220|         9.24|              46.2|\n",
      "|   14|     2.0|                  {}|         127|          69|         3.37|             16.85|\n",
      "|   15|     NaN|                  {}|          25|          61|         2.92|              14.6|\n",
      "|   16|     NaN|                  {}|         212|          81|         5.13|             25.65|\n",
      "|   17|     1.0|                  {}|         166|          24|          1.0|               5.0|\n",
      "|   18|     2.0|                  {}|          75|          75|         0.59|2.9499999999999997|\n",
      "|   19|     NaN|                  {}|          81|          81|          0.0|               0.0|\n",
      "+-----+--------+--------------------+------------+------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duration_rdd.mapPartitions(apply_model_in_batch).toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "07be6e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_predicts = duration_rdd \\\n",
    "              .mapPartitions(apply_model_in_batch) \\\n",
    "              .toDF() \\\n",
    "              .drop('Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicts.select('predicted_duration').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
